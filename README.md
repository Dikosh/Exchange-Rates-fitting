# Exchange-Rates-fitting
Не секрет, что курс рубля напрямую зависит от стоимости нефти (и от кое-чего еще). Этот факт позволяет строить довольно интересные модели. В своей статье о линейной регрессии я коснулся некоторых вопросов, посвященных диагностике модели, а за кадром остался такой вопрос: есть ли более эффективная, но не слишком сложная альтернатива линейной регрессии? Традиционно используемый метод наименьших квадратов прост и понятен, но есть и другие подходы
Временной промежуток — с апреля 2005 по март 2017 года. И вот какая динамика наблюдается за этот период, если выразить стоимость рубля в долларах:
Если судить по графику, то связь между кривыми стоимости рубля и нефти прослеживалась постоянно, но после 2012 г. она стало особенно тесной. В принципе, нет особого смысла строить одну регрессию МНК за все эти года, т.к. в связи с резкими колебаниями цен остатки регрессии будут иметь мультимодальное распределение, и получится модель, которая все плохо описывает. Поэтому рассмотрим период с марта 2015 г. по декабрь 2016 г. — это будет обучающая выборка; данные за 2017 г. используем для тестирования.

Характер связи с 2015 г. не изменился, и линейная регрессия rubi=a+b·oili, построенная с помощью МНК статистически значима:
Если убрать свободный член, то R2 будет почти равен единице. Этому есть объяснение. Как бы это ни было заманчиво, но просто так обнулять свободный член нельзя (разве что исследуемый процесс гарантирует, что линия регрессии проходит через начало координат): кому интересно, можно почитать здесь. Не стоит зацикливаться на R2 — этот критерий достаточно формален. Что касается остатков модели, то они распределены в целом неплохо, но, похоже, бимодально:
Тест Дарбина-Уотсона говорит о наличии (кто бы мог подумать) автокорреляции; коррелограммы остатков указывают на процесс типа AR(1) (об этом мы поговорим ниже). RESET-тест свидетельствует о пропущенных переменных, что логично, т.к. на курс влияет множество факторов (либо МНК — не самая подходящая модель). Все это вместе нарушает предпосылки, которые лежат в основе МНК. Тот, кто занимается эконометрикой, скажет, что пользоваться такой регрессией надо осторожно, т.к. все оценки смещенные и несостоятельные, нельзя строить доверительные интервалы. Из всех свойств сохраняется только линейность.

Можно провернуть еще такой трюк: возможно, зависимость не линейная, а включает и полиномиальные члены. Как выбрать более-менее оптимальную модель? Придется воспользоваться либо перекрестной проверкой, либо информационным критерием типа AIC. Для линейной модели последний мне больше нравится, тем более, что в асимптотике результаты AIC и CV сходятся. Код, приведенный ниже, как раз выполняет то, что нужно: строятся полиномиальные регрессии со степенью от 1 до 5, и на основании минимума критерия AIC определяется оптимальная модель. Функция poly() строит ортогональные полиномы, и именно их надо использовать при регрессии.

which.min(sapply(1:5, function(i) AIC(lm(rub ~ poly(oil, i), data=train))))
## [1] 3


Таким образом, получается, что модель может иметь и такой вид:


Временные ряды и ошибки

О временных рядах можно рассуждать бесконечно и с переменным успехом. Нам же надо знать вот что. И курс рубля, и стоимость нефти являются временными рядами, и не учитывать это нельзя (отсюда и возникают проблемы с ошибками в МНК). Некоторые же процессы можно описать с помощью простой авторегрессионной модели первого порядка. Это означает, что следующее значение во временном ряду хорошо описывается предыдущим плюс небольшая ошибка:


где εt - белый шум.
Построим модель ARIMA с дополнительным регрессором:

ARIMA

Из информации об этой модели можно узнать, что при регрессии rubi=a+b·oili + ui ошибки ui имеют автокорреляционную структуру ARIMA(1, 0, 0), т.е. как раз и представляют собой авторегрессионную модель первого порядка AR(1).

Т.к. теперь структура ошибок приблизительно известна, попробуем обобщенный метод наименьших квадратов (GLS). В GLS используется простая идея, которая заключается в следующем. Если при решении системы y=Xb+ε методом наименьших квадратов коэффициенты при регрессорах и ковариационная матрица находятся из уравнений


то при использовании GLS соответствующие уравнения будут иметь такой вид:


Тут Σ — ковариационная матрица ошибок, которую можно оценить, зная их структуру. В теории такая модель дает несмещенные, эффективные, состоятельные и асимптотически нормальные оценки ( теорема Айткена).

GLS


Можно еще проверить, получим ли мы какую-либо выгоду от включения полиномиальных членов в GLS согласно критерию AIC:

which.min(sapply(1:5, function(i) {
  d <- data.frame(poly(train$oil, i), month=train$month, rub=train$rub)
  AIC(gls(rub ~ . - month, data=d, correlation=corAR1(value=0.7, form=~1|month)))
}))
## [1] 1


Теперь достаточно регрессора в 1 степени. И, кстати, сами скорректированные ошибки модели распределены интереснее (хотя нельзя не отметить наличие выбросов):

im

Регрессия Байеса и вероятностный выбор переменных

К этому моменту у нас есть три модели: OLS, ARIMA(1, 0, 0), GLS с ошибками AR(1). Теперь рассмотрим задачу с другой стороны и в иной постановке, задаваясь прежде всего вопросом, нужны ли нам, например, полиномиальные члены:


Тут записано, что переменная yi распределена нормально и линейно зависит от степеней xi. В свою очередь коэффициенты регрессии не просто распределены нормально, но и еще могут "отсутствовать" в уравнении, что обеспечивается идикаторной переменной Ij, которая подчиняется распределению Бернулли с параметром p, т.е. может принимать только значения 0 или 1. Параметр p в свою очередь берется из бета-распределения, а параметры τ и τb — из гамма. Так мы задали априорные распределения. Откуда известны их точные формы? Вот здесь теория не очень внятная и предлагает опираться либо на наши практические понятия о природе описываемых процессов или интуицию, либо задавать неинформативные априорные распределения. К счастью, чем больше данных доступно, тем меньше вывод зависит от априорных распределений. И это становится понятным, если взглянуть на формулу Байеса, которая представляет собой правило, согласно которому изменяются априорные распределения при наблюдении определенных данных:


Тут p(θ|y) — апостериорное распределение, p(y|θ) — правдоподобие, p(θ) — априорное распределение. Тогда можно записать:


И далее по инерции:


Но все же желательно, чтобы распределения были более-менее осмысленными. Так, если посмотреть на гистограмму yi (у нас это курс рубля), то там можно увидеть кривую, напоминающую нормальное распределение (или логнормальное...). А что касается коэффициентов регрессии, то здесь выбор распределения Гаусса оправдан традиционным ожиданием того, что они распределены нормально.

Конечно, никто не хочет заниматься увлекательным выводом вручную, поэтому нам понадобится библиотека, позволяющая описывать модель в терминах априорных распределений. В R это rjags, и еще функции-обертки из R2jags. Все вышеизложенное запишется в таком виде:

Bayesian Variable Selection

Вывод показывает, что средние значения индикаторных переменных Ij при коэффициентах регрессии b2,...,b5 на порядок меньше I1, а это значит, что такая вероятностная модель дает нам право предположить, что курс рубля линейно зависит от стоимости нефти. Далее запишем простую линейную модель, учитывающую наличие авторегрессии первого порядка в ошибках:

Bayes AR1



Можно заметить, что они не сильно отличаются от параметров модели GLS. Само уравнение регрессии для средних значений параметров можно записать так:


А вот 95% вероятностные интервалы в привычном виде для предсказанных значений курса доллара в 2017 г. (красными треугольниками показаны истинные значения):
image

Заключение

Ниже показан график с предсказаниями курса доллара моделями и их ошибки. Такими вот нехитрыми манипуляциями мы добились уменьшения MAE с 3.1e-04 у OLS до 2.7e-04 при использовании байесовского подхода с учетом авторегрессионного процесса в ошибках модели, причем GLS показал примерно такой же результат, как и байесовский подход, но с меньшими моральными затратами.


Зачем вообще было обращаться к такому выводу, если в итоге мы все равно получили модель, которая не слишком уж и превзошла OLS? Во-первых, теперь формально мы не нарушаем предпосылки к МНК; во-вторых, получили вероятностное подтверждение, что модель все же не включает полиномиальные члены; в-третьих, теперь можно получать вероятностный (а не доверительный!) интервал для интересующей нас величины. Например, если нас интересует, сколько будет стоить доллар в рублях с вероятностью в 95% при стоимости нефти 50.63USD/bbl., то можно получить вот такое распределение:


Конечно, такая регрессия с применением вероятностного вывода требует определенных усилий и некоторого опыта. С другой стороны, если надо что-то быстро посчитать, неохота возиться с распределенями, вероятностные интервалы неинтересны, а ошибки модели коррелированы, то стоит обратить внимание на незаслуженно редко используемый обобщенный метод наименьших квадратов (GLS), который позволяет получать более надежные оценки, чем при слепом использовании OLS. Кроме того, не стоит забывать об auto.arima(), которая позволяет быстро оценить корреляционный процесс в остатках модели.

Bonus

Есть еще интересная и вполне очевидная корреляция — между курсом рубля и международными резервами:

image
Если построить линейную регрессию между этими двумя величинами, то коэффициент детерминации будет равен аж 0.936. Модель с двумя регрессорами (нефть и резервы) имеет R2adj=0.98, и, что самое приятное, RESET-тест Рамсея подтверждает, что в этой регрессии нет пропущенных переменных, т.е. курс рубля вполне себе объясняется стоимостью нефти и международными резервами:


или, если отмасштабировать переменные:

